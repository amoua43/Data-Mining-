{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3b40e6-d003-414f-9ab4-e1d57d527dbb",
   "metadata": {},
   "source": [
    "# **Final Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d5e3d4-9d70-4ffb-b7b0-51fcb25127f2",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "In the digital age, email remains one of the most widely used tools for personal and professional communication. However, with the convenience of email comes a persistent challenge: spam. Spam emails are not only disruptive, but they can also pose significant security risks through phishing attempts and malware distribution. According to Cisco's 2021 Cybersecurity Threat Trends report, nearly 85% of all email traffic is spam, emphasizing the need for robust spam detection systems (Cisco, 2021).\n",
    "\n",
    "This project addresses the problem of accurately classifying email messages as either spam or not spam (ham) using machine learning techniques. Building upon a prior implementation that utilized Logistic Regression and Naive Bayes models, our goal is to improve predictive performance through advanced modeling strategies, better preprocessing, and enhanced feature selection.\n",
    "\n",
    "We are guided by the following research questions:\n",
    "- Can we improve classification accuracy by using more complex models such as ensemble methods?\n",
    "- Which preprocessing strategies (e.g., dimensionality reduction, TF-IDF) lead to better model generalization?\n",
    "- How can we evaluate and compare models effectively based on metrics like precision, recall, F1 score, and confusion matrices?\n",
    "\n",
    "By addressing these questions, our work contributes to a broader understanding of how data science and natural language processing techniques can reduce exposure to unsolicited content and support safer digital communication environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f8004-25d9-4c41-a3fd-ad6321118575",
   "metadata": {},
   "source": [
    "## **About the Data**\n",
    "\n",
    "The dataset used in this project is sourced from Kaggle and was originally published as part of a spam classification challenge (Balaka, 2021). The dataset contains **5,172 rows** (emails) and **3,002 columns**, making it a high-dimensional problem suitable for feature selection and regularization strategies.\n",
    "\n",
    "- The **first column**, `Email No.`, is an identifier for each email and does not carry predictive value.\n",
    "- The **last column**, `Prediction`, is the binary target variable where:\n",
    "  - `1` indicates a spam email,\n",
    "  - `0` indicates a legitimate (ham) email.\n",
    "- The **remaining 3,000 columns** represent the raw word count of individual tokens (words or characters) that appear in the body of each email.\n",
    "\n",
    "This is a **bag-of-words** representation of the emails, where each column represents a word and each row contains the number of times that word appears in a specific email. Because of the dataset's high dimensionality, steps such as removing low-variance features, scaling, or applying dimensionality reduction (e.g., PCA or TF-IDF transformations) are important in preprocessing.\n",
    "\n",
    "This dataset presents a useful benchmark for spam classification tasks, especially given its sparsity and large feature space, making it ideal for exploring the performance of different classification models and feature selection techniques. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c199a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b31d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"emails copy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb88edbd-a9b3-40ef-aa1c-d875a3d87429",
   "metadata": {},
   "source": [
    "## **Methods**\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "We begin by loading the dataset and dropping the `Email No.` column, which serves only as an identifier and holds no predictive value. We verify there are no missing values and remove duplicate records to avoid introducing bias into the training data.\n",
    "\n",
    "To better represent the importance of each word, we apply a **TF-IDF (Term Frequency-Inverse Document Frequency)** transformation. TF-IDF emphasizes rare but informative terms while down-weighting common terms that appear frequently across all documents (Ramos, 2003). This transformation improves model generalization by ensuring that the classifier focuses on features that are more likely to distinguish between spam and non-spam messages. Unlike raw word counts, TF-IDF values normalize for document length and term frequency, helping reduce overfitting and bias.\n",
    "\n",
    "We then perform a **stratified train-test split**, preserving the ratio of spam to non-spam emails in both training and testing sets. This ensures a more reliable and fair evaluation across imbalanced classes.\n",
    "\n",
    "---\n",
    "\n",
    "### Modeling Approaches\n",
    "\n",
    "We experiment with two pipelines designed to evaluate different modeling strategies and dimensionality reduction techniques.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Pipeline 1: TF-IDF → Multinomial Naive Bayes**\n",
    "\n",
    "This pipeline builds directly on the model used in the original project. After transforming the data using TF-IDF, we apply the **Multinomial Naive Bayes** (MNB) classifier. MNB is particularly well-suited for text classification tasks with discrete features like word frequencies or TF-IDF values. It uses Bayes' theorem under a feature independence assumption and performs well even with high-dimensional data (Manning, Raghavan, & Schütze, 2008). This model is efficient, interpretable, and works well on sparse matrices with non-negative values, making it ideal for TF-IDF-transformed data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Pipeline 2: TF-IDF → Truncated SVD → Logistic Regression**\n",
    "\n",
    "To explore further performance improvements, we introduce a second pipeline that includes **dimensionality reduction** through **Truncated Singular Value Decomposition (SVD)**, followed by a **Logistic Regression** classifier.\n",
    "\n",
    "- **Truncated SVD** is used to project high-dimensional TF-IDF vectors into a lower-dimensional latent space, capturing the most informative patterns while reducing noise and redundancy. It is especially effective on sparse matrices (Halko, Martinsson, & Tropp, 2011) and is commonly used in natural language processing applications like latent semantic analysis.\n",
    "\n",
    "- **Logistic Regression** is a linear classifier that models the probability of a binary outcome. It performs well when features are continuous, as is the case with SVD-transformed data. It does not require features to be non-negative and benefits from the de-noising effect of dimensionality reduction, making it a strong candidate for this text classification task (Ng, 2002).\n",
    "\n",
    "Together, TF-IDF and SVD improve the quality and structure of the input space, allowing Logistic Regression to capture meaningful decision boundaries in fewer dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0588052d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Email 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Email 2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Email 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email 4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email 5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
       "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
       "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
       "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
       "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
       "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
       "\n",
       "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0       0    0               0         0         0   0    0           0  \n",
       "1       0    0               0         0         0   1    0           0  \n",
       "2       0    0               0         0         0   0    0           0  \n",
       "3       0    0               0         0         0   0    0           0  \n",
       "4       0    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5a5207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing steps. Determine if there are null values or duplicates. Remove them if they exist.\n",
    "# Drop the 'Email No.' column as it is not relevant.\n",
    "df.drop('Email No.', axis=1, inplace=True)\n",
    "missing_values = df.isnull().sum()\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "801c336f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
       "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
       "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
       "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
       "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
       "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
       "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
       "5167    2   2    2    3    0   0   32    0    0   5  ...         0    0   \n",
       "5168   35  27   11    2    6   5  151    4    3  23  ...         0    0   \n",
       "5169    0   0    1    1    0   0   11    0    0   1  ...         0    0   \n",
       "5170    2   7    1    0    2   1   28    2    0   8  ...         0    0   \n",
       "5171   22  24    5    1    6   5  148    8    2  23  ...         0    0   \n",
       "\n",
       "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0          0    0               0         0         0   0    0           0  \n",
       "1          0    0               0         0         0   1    0           0  \n",
       "2          0    0               0         0         0   0    0           0  \n",
       "3          0    0               0         0         0   0    0           0  \n",
       "4          0    0               0         0         0   1    0           0  \n",
       "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
       "5167       0    0               0         0         0   0    0           0  \n",
       "5168       0    0               0         0         0   1    0           0  \n",
       "5169       0    0               0         0         0   0    0           1  \n",
       "5170       0    0               0         0         0   1    0           1  \n",
       "5171       0    0               0         0         0   0    0           0  \n",
       "\n",
       "[4631 rows x 3001 columns]>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35d79b73-babb-40cd-95c0-667cdf8a1ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + Naive Bayes Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       735\n",
      "           1       0.94      0.62      0.75       300\n",
      "\n",
      "    accuracy                           0.88      1035\n",
      "   macro avg       0.90      0.80      0.84      1035\n",
      "weighted avg       0.89      0.88      0.87      1035\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[724  11]\n",
      " [113 187]]\n"
     ]
    }
   ],
   "source": [
    "# --- Pipeline 1: TF-IDF + Multinomial Naive Bayes ---\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"emails copy.csv\")\n",
    "\n",
    "# Drop the identifier column\n",
    "df.drop(columns=['Email No.'], inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X_counts = df.drop(columns=['Prediction'])\n",
    "y = df['Prediction']\n",
    "\n",
    "# Convert to sparse matrix for memory efficiency\n",
    "X_sparse = csr_matrix(X_counts.values)\n",
    "\n",
    "# Stratified split to preserve spam/ham ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sparse, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfTransformer()),         # Convert raw counts to TF-IDF\n",
    "    ('nb', MultinomialNB())                # Multinomial Naive Bayes classifier\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline_nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_nb = pipeline_nb.predict(X_test)\n",
    "print(\"TF-IDF + Naive Bayes Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b7d08c3-883e-4b30-837e-800889d319db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + SVD + Logistic Regression Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       735\n",
      "           1       0.88      0.77      0.82       300\n",
      "\n",
      "    accuracy                           0.90      1035\n",
      "   macro avg       0.90      0.86      0.88      1035\n",
      "weighted avg       0.90      0.90      0.90      1035\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[704  31]\n",
      " [ 70 230]]\n"
     ]
    }
   ],
   "source": [
    "# --- Pipeline 2: TF-IDF + SVD + Logistic Regression ---\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', TfidfTransformer()),                      # Convert raw counts to TF-IDF\n",
    "    ('svd', TruncatedSVD(n_components=30, random_state=42)),  # Reduce to 30 latent dimensions\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=42)) # Logistic Regression on reduced features\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_lr = pipeline_lr.predict(X_test)\n",
    "print(\"TF-IDF + SVD + Logistic Regression Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f279e0b-9535-45e6-97ba-a3b1761bb6a8",
   "metadata": {},
   "source": [
    "## **Evaluation**\n",
    "\n",
    "To assess the performance of our spam classification models, we compared two pipelines using the same stratified train-test split:\n",
    "\n",
    "1. **TF-IDF → Multinomial Naive Bayes**  \n",
    "2. **TF-IDF → Truncated SVD → Logistic Regression**\n",
    "\n",
    "We used standard classification metrics including **precision**, **recall**, **F1 score**, and overall **accuracy**. Additionally, confusion matrices were analyzed to assess the nature of classification errors.\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline 1: TF-IDF + Multinomial Naive Bayes\n",
    "\n",
    "- **Accuracy**: 88%\n",
    "- **Precision (spam class)**: 0.94\n",
    "- **Recall (spam class)**: 0.62\n",
    "- **F1 Score (spam class)**: 0.75\n",
    "\n",
    "While this pipeline achieved strong precision, it struggled with recall for the spam class, correctly identifying only **62% of actual spam messages**. This suggests that although it made fewer false positives, it was more likely to **miss spam emails** (113 false negatives). The overall F1 score for spam was 0.75.\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline 2: TF-IDF + SVD + Logistic Regression\n",
    "\n",
    "- **Accuracy**: 90%\n",
    "- **Precision (spam class)**: 0.88\n",
    "- **Recall (spam class)**: 0.77\n",
    "- **F1 Score (spam class)**: 0.82\n",
    "\n",
    "This model produced a **more balanced performance**, improving recall from 0.62 to 0.77 while only slightly reducing precision. It identified **230 out of 300 spam emails** correctly, reducing false negatives from 113 to 70. The improvement in F1 score for the spam class (from 0.75 to 0.82) demonstrates the model's better balance between precision and recall.\n",
    "\n",
    "---\n",
    "\n",
    "### Overall Comparison\n",
    "\n",
    "| Metric                | Naive Bayes | Logistic Regression |\n",
    "|----------------------|-------------|---------------------|\n",
    "| Accuracy             | 0.88        | **0.90**            |\n",
    "| Spam Recall (Class 1)| 0.62        | **0.77**            |\n",
    "| Spam Precision       | **0.94**    | 0.88                |\n",
    "| Spam F1 Score        | 0.75        | **0.82**            |\n",
    "| Weighted Avg F1      | 0.87        | **0.90**            |\n",
    "\n",
    "The **Logistic Regression pipeline outperforms** the Naive Bayes model in overall accuracy, F1 score, and especially in **recall**, which is crucial in spam detection tasks. A model with low recall for spam may allow too many malicious emails to reach users. Therefore, we consider the second pipeline to be a more reliable and robust choice for deployment.\n",
    "\n",
    "---\n",
    "\n",
    "Both pipelines benefited from the use of **TF-IDF**, which helped emphasize semantically relevant terms, and the application of a **stratified split**, which ensured balanced representation of spam and ham in the training and test sets.\n",
    "\n",
    "Future improvements could include experimenting with regularization in Logistic Regression, expanding the feature space with n-grams, or using ensemble models such as Random Forest or Gradient Boosting for further performance gains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a427e-6be6-4253-845e-7f3d98cc3808",
   "metadata": {},
   "source": [
    "## **Storytelling and Conclusion**\n",
    "\n",
    "This project began with a simple but real-world relevant goal: improve the performance of a spam detection model originally built using **Multinomial Naive Bayes** and raw word counts. The original model offered a solid baseline, but as we explored deeper into the data and modeling techniques, it became clear there were meaningful opportunities to enhance recall and overall model balance.\n",
    "\n",
    "Through the process, we learned that **preprocessing choices matter deeply**—especially when working with high-dimensional text data. By applying **TF-IDF transformation**, we gave our models the ability to focus on words that were more predictive of spam versus non-spam, rather than just frequent. This adjustment alone made the Naive Bayes model more precise.\n",
    "\n",
    "We then took the project further by incorporating **dimensionality reduction** through **Truncated SVD** and transitioning to **Logistic Regression**. This introduced a shift from generative modeling to discriminative modeling, and the improvement in **recall, accuracy, and F1-score** confirmed that this trade-off was worthwhile. Logistic Regression, although slightly less precise, caught more actual spam, reducing false negatives—arguably the most important type of error in a filtering task.\n",
    "\n",
    "From a data science perspective, this project emphasized the importance of:\n",
    "- Evaluating models on metrics that align with real-world goals (e.g., prioritizing recall for spam detection),\n",
    "- Understanding the assumptions and limitations of different algorithms (e.g., Naive Bayes’ sensitivity to negative input values),\n",
    "- Iterative experimentation—not every technique works right away, and even valid approaches like SVD required adjustment to component size and model compatibility.\n",
    "\n",
    "Our journey from baseline replication to meaningful performance gains shows how even modest changes—when grounded in theory and tested with care—can significantly improve outcomes. The final model is not only more accurate, but also more aligned with the practical needs of spam detection systems.\n",
    "\n",
    "This project also deepened our understanding of NLP workflows, pipeline engineering, model evaluation, and the value of documentation and reproducibility.\n",
    "\n",
    "In a future iteration, we would explore:\n",
    "- Hyperparameter tuning of the `alpha` in Naive Bayes and regularization in Logistic Regression,\n",
    "- Testing n-gram features (e.g., bi-grams) to capture more contextual information,\n",
    "- Applying ensemble models or neural networks for further accuracy,\n",
    "- Addressing potential class imbalance with SMOTE or other re-sampling strategies.\n",
    "\n",
    "Overall, this project illustrates the iterative nature of machine learning, the impact of thoughtful preprocessing, and the importance of aligning modeling decisions with the real-world context of the task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b58ab-e82b-4cbc-a783-e5b4ccdf03a4",
   "metadata": {},
   "source": [
    "## **Impact**\n",
    "\n",
    "Spam detection plays a critical role in protecting users from unwanted content, phishing scams, and harmful links. By improving the recall of our spam classifier—without sacrificing overall accuracy—we contribute to a system that better shields users from malicious content and reduces the cognitive load of sorting through irrelevant messages.\n",
    "\n",
    "Our improved model is particularly impactful in **contexts where missing a spam message has significant consequences**, such as corporate environments or vulnerable populations who may be more susceptible to phishing or financial scams. Enhancing recall means fewer harmful emails go undetected, supporting digital security and user trust.\n",
    "\n",
    "That said, our project also surfaces potential **ethical concerns**. A model that prioritizes spam recall may increase **false positives**, where legitimate emails are incorrectly marked as spam. This could lead to important communications being missed—especially for users whose messages already face systemic biases, such as those writing in non-standard dialects or using informal language more commonly flagged as suspicious. Over-filtering can have real consequences in marginalized communities or in mission-critical communication settings like job applications or healthcare.\n",
    "\n",
    "There are also **privacy considerations**. While our dataset is anonymized, spam detection systems often rely on continuous ingestion of user data. Developers and organizations deploying such models must be transparent about data usage and implement appropriate safeguards to avoid misuse or overreach in content monitoring.\n",
    "\n",
    "Lastly, models trained on historical spam data may inherit outdated biases or fail to adapt to evolving spam techniques. A spam email from 2015 likely differs greatly from those exploiting social engineering trends in 2025. This highlights the importance of continuous retraining and auditing of deployed models.\n",
    "\n",
    "In summary, while our project improves model performance and serves a socially beneficial purpose, it also reminds us of the **importance of fairness, privacy, and adaptability** when developing and deploying real-world machine learning applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da86ab",
   "metadata": {},
   "source": [
    "## **Referrences** \n",
    "* Balaka. (2021). *Email Spam Classification Dataset (CSV)*. Kaggle. https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv/data\n",
    "\n",
    "* Cisco. (2021). *2021 Cybersecurity Threat Trends: Phishing, Crypto Top the List*. Cisco Talos. https://www.cisco.com/c/en/us/products/security/email-security/white-paper-listing.html\n",
    "\n",
    "* Halko, N., Martinsson, P. G., & Tropp, J. A. (2011). *Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions*. SIAM Review, 53(2), 217–288. https://doi.org/10.1137/090771806\n",
    "\n",
    "* Manning, C. D., Raghavan, P., & Schütze, H. (2008). *Introduction to Information Retrieval*. Cambridge University Press.\n",
    "\n",
    "* Ng, A. Y. (2002). *Feature selection, L1 vs. L2 regularization, and rotational invariance*. Proceedings of the 19th International Conference on Machine Learning (ICML).\n",
    "\n",
    "* Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... & Duchesnay, É. (2011). *Scikit-learn: Machine Learning in Python*. Journal of Machine Learning Research, 12, 2825–2830.\n",
    "\n",
    "* Ramos, J. (2003). *Using TF-IDF to determine word relevance in document queries*. In Proceedings of the First Instructional Conference on Machine Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51993e61-4e08-462c-b6eb-ee6747f64d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
